{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T09:10:14.806815Z",
     "iopub.status.busy": "2024-11-18T09:10:14.805979Z",
     "iopub.status.idle": "2024-11-18T09:10:46.256710Z",
     "shell.execute_reply": "2024-11-18T09:10:46.255616Z",
     "shell.execute_reply.started": "2024-11-18T09:10:14.806772Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip install segmentation-models-pytorch\n",
    "# !pip install pytorch_msssim\n",
    "# !pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T09:10:46.258943Z",
     "iopub.status.busy": "2024-11-18T09:10:46.258629Z",
     "iopub.status.idle": "2024-11-18T09:10:51.969250Z",
     "shell.execute_reply": "2024-11-18T09:10:51.968265Z",
     "shell.execute_reply.started": "2024-11-18T09:10:46.258910Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import cv2\n",
    "\n",
    "import zipfile\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T09:10:51.970777Z",
     "iopub.status.busy": "2024-11-18T09:10:51.970406Z",
     "iopub.status.idle": "2024-11-18T09:10:51.975604Z",
     "shell.execute_reply": "2024-11-18T09:10:51.974408Z",
     "shell.execute_reply.started": "2024-11-18T09:10:51.970746Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'EPOCHS':2,\n",
    "    'LEARNING_RATE':3e-4,\n",
    "    # 'BATCH_SIZE':16,\n",
    "    'BATCH_SIZE':64,\n",
    "    'SEED':42\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T09:10:51.978837Z",
     "iopub.status.busy": "2024-11-18T09:10:51.978536Z",
     "iopub.status.idle": "2024-11-18T09:10:51.995977Z",
     "shell.execute_reply": "2024-11-18T09:10:51.995151Z",
     "shell.execute_reply.started": "2024-11-18T09:10:51.978805Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T09:10:51.997364Z",
     "iopub.status.busy": "2024-11-18T09:10:51.997040Z",
     "iopub.status.idle": "2024-11-18T09:10:52.006786Z",
     "shell.execute_reply": "2024-11-18T09:10:52.005771Z",
     "shell.execute_reply.started": "2024-11-18T09:10:51.997332Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#저장된 이미지 쌍을 동시에 로드 \n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, damage_dir, origin_dir, transform=None):\n",
    "        self.damage_dir = damage_dir\n",
    "        self.origin_dir = origin_dir\n",
    "        self.transform = transform\n",
    "        self.damage_files = sorted(os.listdir(damage_dir))\n",
    "        self.origin_files = sorted(os.listdir(origin_dir))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.damage_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        damage_img_name = self.damage_files[idx]\n",
    "        origin_img_name = self.origin_files[idx]\n",
    "\n",
    "        damage_img_path = os.path.join(self.damage_dir, damage_img_name)\n",
    "        origin_img_path = os.path.join(self.origin_dir, origin_img_name)\n",
    "\n",
    "        damage_img = Image.open(damage_img_path).convert(\"RGB\")\n",
    "        origin_img = Image.open(origin_img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            damage_img = self.transform(damage_img)\n",
    "            origin_img = self.transform(origin_img)\n",
    "\n",
    "        return {'A': damage_img, 'B': origin_img}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T09:10:52.008699Z",
     "iopub.status.busy": "2024-11-18T09:10:52.008036Z",
     "iopub.status.idle": "2024-11-18T09:10:54.009497Z",
     "shell.execute_reply": "2024-11-18T09:10:54.008676Z",
     "shell.execute_reply.started": "2024-11-18T09:10:52.008654Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# 경로 설정\n",
    "origin_dir = 'data/train_gt'  # 원본 이미지 폴더 경로\n",
    "damage_dir = 'data/train_input'  # 손상된 이미지 폴더 경로\n",
    "test_dir = 'data/test_input'     # test 이미지 폴더 경로\n",
    "\n",
    "# 데이터 전처리 설정\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "# 전체 데이터셋 생성\n",
    "dataset = CustomDataset(damage_dir=damage_dir, origin_dir=origin_dir, transform=transform)\n",
    "\n",
    "# 데이터셋을 학습과 검증으로 나누기 (예: 80% 학습, 20% 검증)\n",
    "validation_ratio = 0.2\n",
    "train_size = int((1 - validation_ratio) * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "training_dataset, validation_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "\n",
    "# 1. gpt가 짜준 ssimscore랑 공모전 metric 코드랑 뭐가 다른지 비교\n",
    "\n",
    "# 2. bceloss랑 poerceptual loss 들어간 새로운 combined loss로 테스트해보기\n",
    "\n",
    "# # 편법\n",
    "# 3. 1)\n",
    "# train_sizeL 29603 \n",
    "# test: 100\n",
    "# 우리가 갖ㄱ도 있는 최고의의 모데리: 0.5\n",
    "# test=> 대충정답: 컬러사진\n",
    "\n",
    "# 2). 그다음학습 때\n",
    "# training_dataset =>   (0.8*dataset) + + test=> 대충정답: 컬러사진\n",
    "# validation_dataset: (0.2*dataset) + test=> 대충정답: 컬러사진\n",
    "\n",
    "\n",
    "\n",
    "# 학습 및 검증 DataLoader 설정\n",
    "train_dataloader = DataLoader(training_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=True, num_workers=8, prefetch_factor=2)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=8, prefetch_factor=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T09:10:54.010832Z",
     "iopub.status.busy": "2024-11-18T09:10:54.010560Z",
     "iopub.status.idle": "2024-11-18T09:10:54.020829Z",
     "shell.execute_reply": "2024-11-18T09:10:54.019934Z",
     "shell.execute_reply.started": "2024-11-18T09:10:54.010803Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# PatchGAN 기반의 Discriminator\n",
    "class PatchGANDiscriminator(nn.Module):\n",
    "    def __init__(self, in_channels=3):\n",
    "        super(PatchGANDiscriminator, self).__init__()\n",
    "\n",
    "        def discriminator_block(in_filters, out_filters, normalization=True):\n",
    "            layers = [nn.Conv2d(in_filters, out_filters, kernel_size=4, stride=2, padding=1)]\n",
    "            if normalization:\n",
    "                layers.append(nn.BatchNorm2d(out_filters))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return nn.Sequential(*layers)\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            discriminator_block(in_channels * 2, 64, normalization=False),\n",
    "            discriminator_block(64, 128),\n",
    "            discriminator_block(128, 256),\n",
    "            discriminator_block(256, 512),\n",
    "            nn.Conv2d(512, 1, kernel_size=4, padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, img_A, img_B):\n",
    "        img_input = torch.cat((img_A, img_B), 1)\n",
    "        return self.model(img_input)\n",
    "\n",
    "# 가중치 초기화 함수\n",
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm2d') != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T09:10:54.022641Z",
     "iopub.status.busy": "2024-11-18T09:10:54.022016Z",
     "iopub.status.idle": "2024-11-18T09:10:58.148274Z",
     "shell.execute_reply": "2024-11-18T09:10:58.147262Z",
     "shell.execute_reply.started": "2024-11-18T09:10:54.022597Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from segmentation_models_pytorch import UnetPlusPlus\n",
    "\n",
    "# EfficientNet-B4를 백본으로 사용\n",
    "UNetPP = UnetPlusPlus(\n",
    "    encoder_name=\"efficientnet-b4\",  # pretrained on ImageNet\n",
    "    encoder_weights=\"imagenet\",     \n",
    "    in_channels=3,\n",
    "    classes=3\n",
    ").to(device)\n",
    "\n",
    "# generator로 UNetPP를 사용하도록 설정\n",
    "generator = UNetPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-11-17T09:17:16.751926Z",
     "iopub.status.busy": "2024-11-17T09:17:16.751607Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from IPython.display import FileLink\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "# 모델 저장을 위한 디렉토리 생성\n",
    "model_save_dir = \"./saved_models\"\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "log_file = os.path.join(model_save_dir, \"training_log.txt\")\n",
    "\n",
    "# Best score와 loss 초기화\n",
    "best_loss = float(\"inf\")\n",
    "best_score = float(\"-inf\")\n",
    "lambda_pixel = 100  # 픽셀 손실에 대한 가중치\n",
    "\n",
    "# PatchGAN Discriminator 초기화\n",
    "discriminator = PatchGANDiscriminator().to(device)\n",
    "\n",
    "# 손실 함수 및 옵티마이저 설정\n",
    "criterion_GAN = nn.MSELoss()\n",
    "criterion_pixelwise = nn.L1Loss()\n",
    "\n",
    "# Generator와 Discriminator 옵티마이저 설정\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=CFG[\"LEARNING_RATE\"])\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=CFG[\"LEARNING_RATE\"])\n",
    "\n",
    "# 색상 히스토그램 유사도 함수\n",
    "def histogram_similarity(pred, target, bins=256):\n",
    "    pred_hist = cv2.calcHist([pred.cpu().numpy()], [0], None, [bins], [0, 256])\n",
    "    target_hist = cv2.calcHist([target.cpu().numpy()], [0], None, [bins], [0, 256])\n",
    "    hist_similarity = cv2.compareHist(pred_hist, target_hist, cv2.HISTCMP_CORREL)\n",
    "    return hist_similarity\n",
    "\n",
    "# 손실 함수\n",
    "def combined_loss(fake_B, real_B):\n",
    "    loss_GAN = criterion_GAN(fake_B, real_B)\n",
    "    loss_pixel = criterion_pixelwise(fake_B, real_B)\n",
    "    loss_ssim = 1 - ssim(fake_B, real_B, data_range=1.0)\n",
    "    loss_hist = histogram_similarity(fake_B, real_B)\n",
    "    return loss_GAN + lambda_pixel * loss_pixel + 0.4 * loss_ssim + 0.4 * loss_hist\n",
    "\n",
    "def ssim_score(true, pred):\n",
    "    true_np = true.permute(0, 2, 3, 1).cpu().numpy()  # NCHW → NHWC\n",
    "    pred_np = pred.permute(0, 2, 3, 1).cpu().numpy()\n",
    "    ssim_values = []\n",
    "    for t, p in zip(true_np, pred_np):\n",
    "        ssim_values.append(ssim(t, p, channel_axis=-1, data_range=p.max() - p.min()))\n",
    "    return np.mean(ssim_values)\n",
    "\n",
    "def masked_ssim_score(true, pred, mask):\n",
    "    true_np = true.permute(0, 2, 3, 1).cpu().numpy()  # NCHW → NHWC\n",
    "    pred_np = pred.permute(0, 2, 3, 1).cpu().numpy()\n",
    "    mask_np = mask.cpu().numpy()  # 마스크를 NumPy 배열로 변환\n",
    "    masked_ssim_values = []\n",
    "    for t, p, m in zip(true_np, pred_np, mask_np):\n",
    "        true_masked_pixels = t[m > 0]\n",
    "        pred_masked_pixels = p[m > 0]\n",
    "        masked_ssim_values.append(\n",
    "            ssim(\n",
    "                true_masked_pixels, \n",
    "                pred_masked_pixels, \n",
    "                channel_axis=-1, \n",
    "                data_range=pred_masked_pixels.max() - pred_masked_pixels.min()\n",
    "            )\n",
    "        )\n",
    "    return np.mean(masked_ssim_values)\n",
    "\n",
    "def histogram_similarity(true, pred):\n",
    "    true_np = true.permute(0, 2, 3, 1).cpu().numpy().astype(np.uint8)  # NCHW → NHWC\n",
    "    pred_np = pred.permute(0, 2, 3, 1).cpu().numpy().astype(np.uint8)\n",
    "    similarities = []\n",
    "    for t, p in zip(true_np, pred_np):\n",
    "        true_hsv = cv2.cvtColor(t, cv2.COLOR_RGB2HSV)\n",
    "        pred_hsv = cv2.cvtColor(p, cv2.COLOR_RGB2HSV)\n",
    "        hist_true = cv2.calcHist([true_hsv], [0], None, [180], [0, 180])\n",
    "        hist_pred = cv2.calcHist([pred_hsv], [0], None, [180], [0, 180])\n",
    "        hist_true = cv2.normalize(hist_true, hist_true).flatten()\n",
    "        hist_pred = cv2.normalize(hist_pred, hist_pred).flatten()\n",
    "        similarities.append(cv2.compareHist(hist_true, hist_pred, cv2.HISTCMP_CORREL))\n",
    "    return np.mean(similarities)\n",
    "\n",
    "# 학습 및 검증 루프\n",
    "for epoch in range(1, CFG['EPOCHS'] + 1):\n",
    "    generator.train()  # 학습 모드\n",
    "    for i, batch in enumerate(train_dataloader):\n",
    "        real_A = batch['A'].to(device)\n",
    "        real_B = batch['B'].to(device)\n",
    "\n",
    "        # Generator 훈련\n",
    "        optimizer_G.zero_grad()\n",
    "        fake_B = generator(real_A)\n",
    "        pred_fake = discriminator(fake_B, real_A)\n",
    "        loss_GAN = criterion_GAN(pred_fake, torch.ones_like(pred_fake).to(device))\n",
    "        loss_pixel = criterion_pixelwise(fake_B, real_B)\n",
    "        loss_G = loss_GAN + lambda_pixel * loss_pixel\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # Discriminator 훈련\n",
    "        optimizer_D.zero_grad()\n",
    "        pred_real = discriminator(real_B, real_A)\n",
    "        loss_real = criterion_GAN(pred_real, torch.ones_like(pred_real).to(device))\n",
    "        pred_fake = discriminator(fake_B.detach(), real_A)\n",
    "        loss_fake = criterion_GAN(pred_fake, torch.zeros_like(pred_fake).to(device))\n",
    "        loss_D = 0.5 * (loss_real + loss_fake)\n",
    "        loss_D.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # Discriminator 정확도 계산\n",
    "        real_accuracy = torch.mean((pred_real > 0.5).float())\n",
    "        fake_accuracy = torch.mean((pred_fake < 0.5).float())\n",
    "        accuracy = 0.5 * (real_accuracy + fake_accuracy)\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f\"[Epoch {epoch}/{CFG['EPOCHS']}] [Batch {i}/{len(train_dataloader)}] \"\n",
    "                  f\"[D loss: {loss_D.item()}] [G loss: {loss_G.item()}] [D accuracy: {accuracy.item() * 100:.2f}%]\")\n",
    "\n",
    "        # Validation 및 모델 저장\n",
    "        if (i + 1) % 10 == 0 or i == len(train_dataloader) - 1:  # 10배치마다 또는 마지막 배치마다 저장\n",
    "            try:\n",
    "                generator.eval()\n",
    "                validation_loss = 0.0\n",
    "                with torch.no_grad():\n",
    "                    for val_batch in validation_dataloader:\n",
    "                        real_val_A = val_batch['A'].to(device)\n",
    "                        real_val_B = val_batch['B'].to(device)\n",
    "                        fake_val_B = generator(real_val_A)\n",
    "                        val_loss = combined_loss(fake_val_B, real_val_B)\n",
    "                        validation_loss += val_loss.item()\n",
    "\n",
    "                validation_loss /= len(validation_dataloader)\n",
    "                print(f\"Validation loss at Epoch {epoch}, Batch {i + 1}: {validation_loss}\")\n",
    "\n",
    "                # 모델 저장\n",
    "                if validation_loss < best_loss:\n",
    "                    best_loss = validation_loss\n",
    "                    torch.save(generator.state_dict(), os.path.join(model_save_dir, f\"best_generator_epoch{epoch}_batch{i + 1}.pth\"))\n",
    "                    torch.save(discriminator.state_dict(), os.path.join(model_save_dir, f\"best_discriminator_epoch{epoch}_batch{i + 1}.pth\"))\n",
    "                    print(f\"Best model saved at Epoch {epoch}, Batch {i + 1} with Validation loss: {validation_loss}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error during validation or saving: {e}\")\n",
    "\n",
    "\n",
    "    # Validation 단계\n",
    "    generator.eval()  # 검증 모드\n",
    "    validation_loss = 0.0\n",
    "    ssim_scores, masked_ssim_scores, hist_similarities = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for val_batch in validation_dataloader:\n",
    "            real_val_A = val_batch['A'].to(device)  # 손실 영역 마스크\n",
    "            real_val_B = val_batch['B'].to(device)  # Ground Truth\n",
    "            fake_val_B = generator(real_val_A)      # 복원된 이미지\n",
    "    \n",
    "            # 각각의 스코어 계산\n",
    "            ssim_value = ssim_score(real_val_B, fake_val_B)\n",
    "            masked_ssim_value = masked_ssim_score(real_val_B, fake_val_B, real_val_A)\n",
    "            hist_value = histogram_similarity(real_val_B, fake_val_B)\n",
    "    \n",
    "            ssim_scores.append(ssim_value)\n",
    "            masked_ssim_scores.append(masked_ssim_value)\n",
    "            hist_similarities.append(hist_value)\n",
    "    \n",
    "            val_loss = combined_loss(fake_val_B, real_val_B)\n",
    "            validation_loss += val_loss.item()\n",
    "    \n",
    "    # 평균 스코어 계산\n",
    "    S = sum(ssim_scores) / len(ssim_scores)\n",
    "    M = sum(masked_ssim_scores) / len(masked_ssim_scores)\n",
    "    C = sum(hist_similarities) / len(hist_similarities)\n",
    "    score = (0.2 * S) + (0.4 * M) + (0.4 * C)\n",
    "    \n",
    "    validation_loss /= len(validation_dataloader)\n",
    "    validation_log_message = f\"Validation loss: {validation_loss}, Score: {score}\"\n",
    "    print(validation_log_message)\n",
    "    \n",
    "    # 텍스트 파일에 Validation 손실 기록\n",
    "    with open(log_file, \"a\") as log:\n",
    "        log.write(validation_log_message + \"\\n\")\n",
    "    \n",
    "    # SSIM 평가 기준에 따른 최적 모델 저장\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        torch.save(generator.state_dict(), os.path.join(model_save_dir, \"best_generator.pth\"))\n",
    "        torch.save(discriminator.state_dict(), os.path.join(model_save_dir, \"best_discriminator.pth\"))\n",
    "        save_message = f\"Best model saved at epoch {epoch} with Score: {score}\"\n",
    "        print(save_message)\n",
    "        with open(log_file, \"a\") as log:\n",
    "            log.write(save_message + \"\\n\")\n",
    "\n",
    "# 학습 완료 후 최고의 스코어 출력\n",
    "final_message = f\"Training completed. Best Score: {best_score}\"\n",
    "print(final_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T09:11:36.631338Z",
     "iopub.status.busy": "2024-11-18T09:11:36.630923Z",
     "iopub.status.idle": "2024-11-18T09:11:47.123872Z",
     "shell.execute_reply": "2024-11-18T09:11:47.122821Z",
     "shell.execute_reply.started": "2024-11-18T09:11:36.631300Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30/3045569111.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  UNetPP.load_state_dict(torch.load(generator_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved all images\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 저장할 디렉토리 설정\n",
    "model_save_dir = \"./saved_models\"\n",
    "submission_dir = \"./submission\"\n",
    "os.makedirs(submission_dir, exist_ok=True)\n",
    "\n",
    "# 이미지 로드 및 전처리\n",
    "def load_image(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = transform(image)\n",
    "    image = image.unsqueeze(0)  # 배치 차원을 추가합니다.\n",
    "    return image\n",
    "\n",
    "# 모델 경로 설정\n",
    "generator_path = os.path.join(\"/kaggle/input/best-model01/best_generator (1).pth\")\n",
    "\n",
    "# 모델 로드 및 설정\n",
    "# model = UNetPP(in_channels=3, out_channels=3).to(device)  # UNetPP로 설정\n",
    "UNetPP.load_state_dict(torch.load(generator_path))\n",
    "UNetPP.eval()\n",
    "\n",
    "# 파일 리스트 불러오기\n",
    "test_images = sorted(os.listdir(test_dir))\n",
    "\n",
    "# 모든 테스트 이미지에 대해 추론 수행\n",
    "for image_name in test_images:\n",
    "    test_image_path = os.path.join(test_dir, image_name)\n",
    "\n",
    "    # 손상된 테스트 이미지 로드 및 전처리\n",
    "    test_image = load_image(test_image_path).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # 모델로 예측\n",
    "        pred_image = UNetPP(test_image)\n",
    "        pred_image = pred_image.cpu().squeeze(0)  # 배치 차원 제거\n",
    "        pred_image = pred_image * 0.5 + 0.5  # 역정규화\n",
    "        pred_image = pred_image.numpy().transpose(1, 2, 0)  # HWC로 변경\n",
    "        pred_image = (pred_image * 255).astype('uint8')  # 0-255 범위로 변환\n",
    "        \n",
    "        # 예측된 이미지를 실제 이미지와 같은 512x512로 리사이즈\n",
    "        pred_image_resized = cv2.resize(pred_image, (512, 512), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    # 결과 이미지 저장\n",
    "    output_path = os.path.join(submission_dir, image_name)\n",
    "    cv2.imwrite(output_path, cv2.cvtColor(pred_image_resized, cv2.COLOR_RGB2BGR))    \n",
    "    \n",
    "print(f\"Saved all images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T09:11:51.006020Z",
     "iopub.status.busy": "2024-11-18T09:11:51.005310Z",
     "iopub.status.idle": "2024-11-18T09:11:51.130683Z",
     "shell.execute_reply": "2024-11-18T09:11:51.129745Z",
     "shell.execute_reply.started": "2024-11-18T09:11:51.005970Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All images saved in submission1.zip\n"
     ]
    }
   ],
   "source": [
    "# 저장된 결과 이미지를 ZIP 파일로 압축\n",
    "zip_filename = \"submission1.zip\"\n",
    "with zipfile.ZipFile(zip_filename, 'w') as submission_zip:\n",
    "    for image_name in test_images:\n",
    "        image_path = os.path.join(submission_dir, image_name)\n",
    "        submission_zip.write(image_path, arcname=image_name)\n",
    "\n",
    "print(f\"All images saved in {zip_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T02:15:56.140763Z",
     "iopub.status.busy": "2024-11-15T02:15:56.140088Z",
     "iopub.status.idle": "2024-11-15T02:15:57.214677Z",
     "shell.execute_reply": "2024-11-15T02:15:57.213429Z",
     "shell.execute_reply.started": "2024-11-15T02:15:56.140720Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m.\u001b[0m\n",
      "`-- \u001b[01;34msubmission\u001b[0m\n",
      "\n",
      "1 directory, 0 files\n"
     ]
    }
   ],
   "source": [
    "!tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6075062,
     "sourceId": 9891694,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6078662,
     "sourceId": 9896364,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6111024,
     "sourceId": 9939640,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "tensorflow-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
