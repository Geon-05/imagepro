{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip install segmentation-models-pytorch\n",
    "# !pip install pytorch_msssim\n",
    "# !pip install lightning\n",
    "# !pip install lightning[extra]\n",
    "# !pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T11:43:51.186648Z",
     "iopub.status.busy": "2024-11-19T11:43:51.186234Z",
     "iopub.status.idle": "2024-11-19T11:43:56.207750Z",
     "shell.execute_reply": "2024-11-19T11:43:56.206634Z",
     "shell.execute_reply.started": "2024-11-19T11:43:51.186605Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import cv2\n",
    "\n",
    "import zipfile\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "0\n",
      "NVIDIA GeForce RTX 4070 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())  # True인지 확인\n",
    "print(torch.cuda.device_count())  # 사용 가능한 GPU 개수 확인\n",
    "print(torch.cuda.current_device())  # 현재 사용 중인 GPU 인덱스 확인\n",
    "print(torch.cuda.get_device_name(0))  # 사용 중인 GPU 이름 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T09:26:37.561283Z",
     "iopub.status.busy": "2024-11-18T09:26:37.560230Z",
     "iopub.status.idle": "2024-11-18T09:26:37.565711Z",
     "shell.execute_reply": "2024-11-18T09:26:37.564720Z",
     "shell.execute_reply.started": "2024-11-18T09:26:37.561236Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'EPOCHS':2,\n",
    "    'LEARNING_RATE':3e-4,\n",
    "    # 'BATCH_SIZE':16,\n",
    "    'BATCH_SIZE':64,\n",
    "    'SEED':42\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T09:26:42.306099Z",
     "iopub.status.busy": "2024-11-18T09:26:42.305720Z",
     "iopub.status.idle": "2024-11-18T09:26:42.312781Z",
     "shell.execute_reply": "2024-11-18T09:26:42.311930Z",
     "shell.execute_reply.started": "2024-11-18T09:26:42.306061Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_input_image(image):\n",
    "    # 이 함수는 손상된 이미지로부터 마스크를 생성하여 반환합니다.\n",
    "    # 예시: 특정 조건에 따라 임의로 마스크 생성 (여기서는 단순히 모든 픽셀을 마스크로 가정)\n",
    "    \n",
    "    # 손상된 이미지의 그레이스케일 버전과 마스크 생성 (단순한 예제)\n",
    "    image_gray = image.convert(\"L\")\n",
    "    mask = np.array(image_gray) > 128  # 임의의 임계값 기준으로 마스크 생성\n",
    "    mask = Image.fromarray(mask.astype(np.uint8) * 255)  # 마스크 이미지를 PIL 형식으로 변환\n",
    "    \n",
    "    return {\n",
    "        'image_gray_masked': image_gray,\n",
    "        'mask': transforms.ToTensor()(mask)  # 마스크를 텐서로 변환하여 사용\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T09:26:43.916202Z",
     "iopub.status.busy": "2024-11-18T09:26:43.915467Z",
     "iopub.status.idle": "2024-11-18T09:26:43.924099Z",
     "shell.execute_reply": "2024-11-18T09:26:43.923177Z",
     "shell.execute_reply.started": "2024-11-18T09:26:43.916150Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, damage_dir, origin_dir, transform=None, use_masks=False):\n",
    "        self.damage_dir = damage_dir\n",
    "        self.origin_dir = origin_dir\n",
    "        self.transform = transform\n",
    "        self.use_masks = use_masks  # 마스크 사용 여부\n",
    "        self.damage_files = sorted(os.listdir(damage_dir))\n",
    "        self.origin_files = sorted(os.listdir(origin_dir))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.damage_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        damage_img_name = self.damage_files[idx]\n",
    "        origin_img_name = self.origin_files[idx]\n",
    "\n",
    "        damage_img_path = os.path.join(self.damage_dir, damage_img_name)\n",
    "        origin_img_path = os.path.join(self.origin_dir, origin_img_name)\n",
    "\n",
    "        damage_img = Image.open(damage_img_path).convert(\"RGB\")\n",
    "        origin_img = Image.open(origin_img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.use_masks:\n",
    "            input_data = get_input_image(damage_img)  # 손상된 이미지에서 마스크 생성\n",
    "            mask = input_data['mask']\n",
    "            damage_img = input_data['image_gray_masked']\n",
    "        else:\n",
    "            mask = torch.zeros((1, damage_img.size[1], damage_img.size[0]))  # 빈 마스크 생성\n",
    "\n",
    "        if self.transform:\n",
    "            damage_img = self.transform(damage_img)\n",
    "            origin_img = self.transform(origin_img)\n",
    "\n",
    "        return {'A': damage_img, 'B': origin_img, 'mask': mask}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T09:26:45.211962Z",
     "iopub.status.busy": "2024-11-18T09:26:45.211580Z",
     "iopub.status.idle": "2024-11-18T09:26:45.225539Z",
     "shell.execute_reply": "2024-11-18T09:26:45.224565Z",
     "shell.execute_reply.started": "2024-11-18T09:26:45.211924Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zqrc0\\anaconda3\\envs\\new_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from segmentation_models_pytorch import UnetPlusPlus\n",
    "import torch.nn.functional as F\n",
    "import lightning as L\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def get_histogram_similarity(true, pred, color_space=cv2.COLOR_RGB2HSV):\n",
    "    # PyTorch 텐서를 NumPy 배열로 변환하고 차원을 조정\n",
    "    true_np = true.permute(1, 2, 0).cpu().numpy().astype(np.uint8)\n",
    "    pred_np = pred.permute(1, 2, 0).cpu().numpy().astype(np.uint8)\n",
    "    \n",
    "    # 히스토그램 유사도 계산\n",
    "    true_hsv = cv2.cvtColor(true_np, color_space)\n",
    "    pred_hsv = cv2.cvtColor(pred_np, color_space)\n",
    "    \n",
    "    # 히스토그램 계산 및 비교\n",
    "    hist_true = cv2.calcHist([true_hsv], [0], None, [180], [0, 180])\n",
    "    hist_pred = cv2.calcHist([pred_hsv], [0], None, [180], [0, 180])\n",
    "    \n",
    "    hist_true = cv2.normalize(hist_true, hist_true).flatten()\n",
    "    hist_pred = cv2.normalize(hist_pred, hist_pred).flatten()\n",
    "    \n",
    "    similarity = cv2.compareHist(hist_true, hist_pred, cv2.HISTCMP_CORREL)\n",
    "    \n",
    "    return similarity\n",
    "\n",
    "def get_masked_ssim_score(true, pred, mask):\n",
    "    # PyTorch 텐서를 NumPy 배열로 변환하고, 차원을 조정\n",
    "    true_np = true.permute(1, 2, 0).cpu().numpy()\n",
    "    pred_np = pred.permute(1, 2, 0).cpu().numpy()\n",
    "    mask_np = mask.permute(1, 2, 0).cpu().numpy()\n",
    "\n",
    "    # 마스크가 적용된 부분만 추출\n",
    "    true_masked = true_np[mask_np > 0]\n",
    "    pred_masked = pred_np[mask_np > 0]\n",
    "\n",
    "    if true_masked.size == 0 or pred_masked.size == 0:\n",
    "        return 0  # 마스크된 부분이 없으면 SSIM을 0으로 처리\n",
    "\n",
    "    # SSIM 계산\n",
    "    ssim_value = ssim(\n",
    "        true_masked, pred_masked, data_range=pred_masked.max() - pred_masked.min(), channel_axis=-1\n",
    "    )\n",
    "    return ssim_value\n",
    "\n",
    "def ssim_score(true, pred):\n",
    "    true_np = true.permute(0, 2, 3, 1).cpu().numpy()\n",
    "    pred_np = pred.permute(0, 2, 3, 1).cpu().numpy()\n",
    "    scores = [\n",
    "        ssim(t, p, channel_axis=-1, data_range=p.max() - p.min())\n",
    "        for t, p in zip(true_np, pred_np)\n",
    "    ]\n",
    "    return np.mean(scores)\n",
    "\n",
    "def get_ssim_score(true, pred):\n",
    "    # PyTorch 텐서를 NumPy 배열로 변환하고, 차원을 조정\n",
    "    true_np = true.permute(0, 2, 3, 1).cpu().numpy()\n",
    "    pred_np = pred.permute(0, 2, 3, 1).cpu().numpy()\n",
    "    scores = [\n",
    "        ssim(t, p, channel_axis=-1, data_range=p.max() - p.min())\n",
    "        for t, p in zip(true_np, pred_np)\n",
    "    ]\n",
    "    return np.mean(scores)\n",
    "\n",
    "# LitIRModel 클래스 정의\n",
    "class LitIRModel(L.LightningModule):\n",
    "    def __init__(self, model_1, model_2, image_mean=0.5, image_std=0.5):\n",
    "        super().__init__()\n",
    "        self.model_1 = model_1\n",
    "        self.model_2 = model_2\n",
    "        self.image_mean = image_mean\n",
    "        self.image_std = image_std\n",
    "\n",
    "    def forward(self, images_gray_masked):\n",
    "        # 첫 번째 모델: Gray Mask Restoration\n",
    "        images_gray_restored = self.model_1(images_gray_masked) + images_gray_masked\n",
    "        # 두 번째 모델: Gray → Color\n",
    "        images_restored = self.model_2(images_gray_restored)\n",
    "        return images_gray_restored, images_restored\n",
    "\n",
    "    def unnormalize(self, output, round=False):\n",
    "        # 출력값을 unnormalize\n",
    "        image_restored = ((output * self.image_std + self.image_mean) * 255).clamp(0, 255)\n",
    "        if round:\n",
    "            image_restored = torch.round(image_restored)\n",
    "        return image_restored\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # AdamW Optimizer\n",
    "        opt = torch.optim.AdamW(self.parameters(), lr=1e-5)\n",
    "        return opt\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # GPU 이동 명시적으로 지정\n",
    "        images_gray_masked = batch['images_gray_masked'].to(self.device)\n",
    "        images_gt = batch['images_gt'].to(self.device)\n",
    "        \n",
    "        # Forward pass\n",
    "        images_gray_restored, images_restored = self(images_gray_masked)\n",
    "        \n",
    "        # Forward pass\n",
    "        images_gray_restored, images_restored = self(images_gray_masked)\n",
    "\n",
    "        # Loss 계산\n",
    "        loss_pixel_gray = (\n",
    "            F.l1_loss(images_gray, images_gray_restored, reduction='mean') * 0.5 +\n",
    "            F.mse_loss(images_gray, images_gray_restored, reduction='mean') * 0.5\n",
    "        )\n",
    "        loss_pixel = (\n",
    "            F.l1_loss(images_gt, images_restored, reduction='mean') * 0.5 +\n",
    "            F.mse_loss(images_gt, images_restored, reduction='mean') * 0.5\n",
    "        )\n",
    "        loss = loss_pixel_gray * 0.5 + loss_pixel * 0.5\n",
    "\n",
    "        print(f\"Batch {batch_idx}, Loss: {loss.item()}\")\n",
    "        # Logging (매 배치마다 메트릭을 로깅하지 않고, 에폭 종료 시 로깅)\n",
    "        self.log(\"train_loss\", loss, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # 10번째 배치마다 메트릭 계산\n",
    "        if batch_idx % 10 == 0:\n",
    "            masks, images_gray_masked, images_gt = (\n",
    "                batch['masks'], batch['images_gray_masked'], batch['images_gt']\n",
    "            )\n",
    "            images_gray_restored, images_restored = self(images_gray_masked)\n",
    "\n",
    "            # Unnormalize for evaluation\n",
    "            images_gt, images_restored = self.unnormalize(images_gt, round=True), self.unnormalize(images_restored, round=True)\n",
    "            masks_np = masks.detach().cpu().numpy()\n",
    "            images_gt_np = images_gt.detach().cpu().permute(0, 2, 3, 1).float().numpy().astype(np.uint8)\n",
    "            images_restored_np = images_restored.detach().cpu().permute(0, 2, 3, 1).float().numpy().astype(np.uint8)\n",
    "\n",
    "            # Metric 계산\n",
    "            total_ssim_score = 0\n",
    "            masked_ssim_score = 0\n",
    "            hist_sim_score = 0\n",
    "            for image_gt_np, image_restored_np, mask_np in zip(images_gt_np, images_restored_np, masks_np):\n",
    "                total_ssim_score += get_ssim_score(image_gt_np, image_restored_np) / len(images_gt)\n",
    "                masked_ssim_score += get_masked_ssim_score(image_gt_np, image_restored_np, mask_np) / len(images_gt)\n",
    "                hist_sim_score += get_histogram_similarity(image_gt_np, image_restored_np, cv2.COLOR_RGB2HSV) / len(images_gt)\n",
    "\n",
    "            # 최종 점수\n",
    "            score = total_ssim_score * 0.2 + masked_ssim_score * 0.4 + hist_sim_score * 0.4\n",
    "\n",
    "            # Logging\n",
    "            self.log(f\"val_score\", score, on_step=False, on_epoch=True)\n",
    "            self.log(f\"val_total_ssim_score\", total_ssim_score, on_step=False, on_epoch=True)\n",
    "            self.log(f\"val_masked_ssim_score\", masked_ssim_score, on_step=False, on_epoch=True)\n",
    "            self.log(f\"val_hist_sim_score\", hist_sim_score, on_step=False, on_epoch=True)\n",
    "\n",
    "        return None  # loss 반환 필요 없음\n",
    "\n",
    "# 모델 초기화\n",
    "# 첫 번째 모델: Gray Mask Restoration\n",
    "model_1 = UnetPlusPlus(\n",
    "    encoder_name=\"efficientnet-b4\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    in_channels=1,\n",
    "    classes=1\n",
    ")\n",
    "\n",
    "# 두 번째 모델: Gray → Color\n",
    "model_2 = UnetPlusPlus(\n",
    "    encoder_name=\"efficientnet-b4\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    in_channels=1,\n",
    "    classes=3\n",
    ")\n",
    "\n",
    "# LitIRModel 초기화\n",
    "lit_ir_model = LitIRModel(model_1=model_1, model_2=model_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T09:26:44.518238Z",
     "iopub.status.busy": "2024-11-18T09:26:44.517833Z",
     "iopub.status.idle": "2024-11-18T09:26:44.581574Z",
     "shell.execute_reply": "2024-11-18T09:26:44.580853Z",
     "shell.execute_reply.started": "2024-11-18T09:26:44.518201Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import lightning as L\n",
    "\n",
    "# 경로 설정\n",
    "origin_dir = 'data/train_gt'  # 원본 이미지 폴더 경로\n",
    "damage_dir = 'data/train_input'  # 손상된 이미지 폴더 경로\n",
    "test_dir = 'data/test_input'     # test 이미지 폴더 경로\n",
    "\n",
    "# 데이터 전처리 설정\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "# 전체 데이터셋 생성\n",
    "dataset = CustomDataset(damage_dir=damage_dir, origin_dir=origin_dir, transform=transform)\n",
    "\n",
    "# 데이터셋을 학습과 검증으로 나누기 (예: 80% 학습, 20% 검증)\n",
    "validation_ratio = 0.2\n",
    "train_size = int((1 - validation_ratio) * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "training_dataset, validation_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "class CollateFn:\n",
    "    def __init__(self, mode='train'):\n",
    "        self.mode = mode\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        # 'batch'는 각 데이터 샘플로 이루어진 리스트이며, 각 샘플은 {'A': tensor, 'B': tensor, 'mask': tensor or None} 형태\n",
    "        A = torch.stack([item['A'] for item in batch])\n",
    "        B = torch.stack([item['B'] for item in batch])\n",
    "        \n",
    "        if batch[0]['mask'] is not None:\n",
    "            masks = torch.stack([item['mask'] for item in batch])\n",
    "        else:\n",
    "            masks = None\n",
    "        \n",
    "        if self.mode == 'train':\n",
    "            return {'A': A, 'B': B, 'mask': masks}\n",
    "        elif self.mode == 'valid':\n",
    "            return {'A': A, 'B': B, 'mask': masks}\n",
    "\n",
    "# DataLoader 설정 시 사용할 수 있도록 CollateFn 클래스 추가\n",
    "train_collate_fn = CollateFn(mode='train')\n",
    "validation_collate_fn = CollateFn(mode='valid')\n",
    "\n",
    "# 학습 및 검증 DataLoader 설정\n",
    "train_dataloader = DataLoader(\n",
    "    training_dataset,\n",
    "    batch_size=CFG['BATCH_SIZE'],\n",
    "    shuffle=True,\n",
    "    num_workers=8,\n",
    "    pin_memory=True,  # 이 옵션 추가\n",
    "    collate_fn=train_collate_fn\n",
    ")\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "    validation_dataset,\n",
    "    batch_size=CFG['BATCH_SIZE'],\n",
    "    shuffle=False,\n",
    "    num_workers=8,\n",
    "    collate_fn=validation_collate_fn\n",
    ")\n",
    "\n",
    "# DataLoader에서 배치 데이터를 GPU로 이동\n",
    "for batch in train_dataloader:\n",
    "    inputs = batch['A'].to(device)\n",
    "    targets = batch['B'].to(device)\n",
    "\n",
    "\n",
    "\n",
    "# 모델 저장 디렉토리 생성\n",
    "model_save_dir = \"./saved_models\"\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "\n",
    "# 3. Trainer 설정 및 학습 시작\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=CFG['EPOCHS'],\n",
    "    precision=16,\n",
    "    accelerator='gpu',\n",
    "    devices=1,\n",
    "    log_every_n_steps=10,  # 매 10번째 스텝마다 로그를 남기도록 설정\n",
    "    callbacks=[\n",
    "        ModelCheckpoint(\n",
    "            monitor='val_score',\n",
    "            mode='max',\n",
    "            save_top_k=1,\n",
    "            dirpath=model_save_dir,\n",
    "            filename='best_model-{epoch:02d}-{val_score:.4f}'\n",
    "        ),\n",
    "        EarlyStopping(monitor='val_score', mode='max', patience=3)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 학습 시작\n",
    "trainer.fit(lit_ir_model, train_dataloader, validation_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T09:27:56.438758Z",
     "iopub.status.busy": "2024-11-18T09:27:56.438385Z",
     "iopub.status.idle": "2024-11-18T09:27:56.541688Z",
     "shell.execute_reply": "2024-11-18T09:27:56.540480Z",
     "shell.execute_reply.started": "2024-11-18T09:27:56.438716Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import DataLoader\n",
    "# from IPython.display import FileLink\n",
    "# import numpy as np\n",
    "# from skimage.metrics import structural_similarity as ssim\n",
    "# import cv2\n",
    "# import torch.nn.functional as F\n",
    "# from lightning.pytorch import Trainer\n",
    "\n",
    "# class GeneratorModel(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(GeneratorModel, self).__init__()\n",
    "#         # 예시로 간단한 U-Net 아키텍처를 사용\n",
    "#         self.encoder = nn.Sequential(\n",
    "#             nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1),\n",
    "#             nn.ReLU(True),\n",
    "#             nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "#             nn.BatchNorm2d(128),\n",
    "#             nn.ReLU(True)\n",
    "#         )\n",
    "#         self.decoder = nn.Sequential(\n",
    "#             nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "#             nn.BatchNorm2d(64),\n",
    "#             nn.ReLU(True),\n",
    "#             nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1),\n",
    "#             nn.Tanh()\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.encoder(x)\n",
    "#         x = self.decoder(x)\n",
    "#         return x\n",
    "    \n",
    "# class PatchGANDiscriminator(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(PatchGANDiscriminator, self).__init__()\n",
    "#         self.model = nn.Sequential(\n",
    "#             nn.Conv2d(6, 64, kernel_size=4, stride=2, padding=1),  # Real 이미지와 Fake 이미지가 concatenated 된 상태로 입력됨 (3+3=6 채널)\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "#             nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "#             nn.BatchNorm2d(128),\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "#             nn.Conv2d(128, 1, kernel_size=4, stride=1, padding=1)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x, y):\n",
    "#         # x는 손상된 이미지, y는 생성된 이미지 또는 원본 이미지\n",
    "#         input = torch.cat([x, y], dim=1)  # 두 이미지를 채널 차원에서 concatenate\n",
    "#         return self.model(input)\n",
    "\n",
    "# # CUDA 성능 최적화를 위한 설정\n",
    "# torch.backends.cudnn.benchmark = True  # 입력 크기가 일정하다면 성능을 최적화합니다.\n",
    "# torch.backends.cudnn.enabled = True\n",
    "\n",
    "# # 모델 저장 디렉토리 생성\n",
    "# model_save_dir = \"./saved_models\"\n",
    "# os.makedirs(model_save_dir, exist_ok=True)\n",
    "# log_file = os.path.join(model_save_dir, \"training_log.txt\")\n",
    "\n",
    "# # 초기값 설정\n",
    "# best_loss = float(\"inf\")\n",
    "# best_score = float(\"-inf\")\n",
    "# lambda_pixel = 100  # 픽셀 손실 가중치\n",
    "\n",
    "# # 손실 함수 정의\n",
    "# criterion_GAN = nn.MSELoss()\n",
    "# criterion_pixelwise = nn.L1Loss()\n",
    "\n",
    "# # 히스토그램 유사도 계산 함수\n",
    "# def histogram_similarity(true, pred):\n",
    "#     true_np = true.permute(0, 2, 3, 1).cpu().numpy().astype(np.uint8)\n",
    "#     pred_np = pred.permute(0, 2, 3, 1).cpu().numpy().astype(np.uint8)\n",
    "#     similarities = []\n",
    "#     for t, p in zip(true_np, pred_np):\n",
    "#         true_hsv = cv2.cvtColor(t, cv2.COLOR_RGB2HSV)\n",
    "#         pred_hsv = cv2.cvtColor(p, cv2.COLOR_RGB2HSV)\n",
    "#         hist_true = cv2.calcHist([true_hsv], [0], None, [180], [0, 180])\n",
    "#         hist_pred = cv2.calcHist([pred_hsv], [0], None, [180], [0, 180])\n",
    "#         hist_true = cv2.normalize(hist_true, hist_true).flatten()\n",
    "#         hist_pred = cv2.normalize(hist_pred, hist_pred).flatten()\n",
    "#         similarities.append(cv2.compareHist(hist_true, hist_pred, cv2.HISTCMP_CORREL))\n",
    "#     return np.mean(similarities)\n",
    "\n",
    "# # SSIM 점수 계산 함수\n",
    "# def ssim_score(true, pred):\n",
    "#     true_np = true.permute(0, 2, 3, 1).cpu().numpy()\n",
    "#     pred_np = pred.permute(0, 2, 3, 1).cpu().numpy()\n",
    "#     scores = [ssim(t, p, channel_axis=-1, data_range=p.max() - p.min()) for t, p in zip(true_np, pred_np)]\n",
    "#     return np.mean(scores)\n",
    "\n",
    "# # Masked SSIM 점수 계산 함수 (데이터 크기 조정 오류 수정)\n",
    "# def masked_ssim_score(true, pred, mask):\n",
    "#     true_np = true.permute(0, 2, 3, 1).cpu().numpy()\n",
    "#     pred_np = pred.permute(0, 2, 3, 1).cpu().numpy()\n",
    "#     mask_np = mask.permute(0, 2, 3, 1).cpu().numpy()  # mask의 크기를 이미지와 동일하게 조정\n",
    "#     scores = []\n",
    "#     for t, p, m in zip(true_np, pred_np, mask_np):\n",
    "#         if m.any():  # 마스크에 유효한 값이 있을 때만 계산\n",
    "#             true_masked = t[m > 0]\n",
    "#             pred_masked = p[m > 0]\n",
    "#             if true_masked.size > 0 and pred_masked.size > 0:  # 유효한 픽셀이 존재할 때만 계산\n",
    "#                 scores.append(\n",
    "#                     ssim(\n",
    "#                         true_masked, pred_masked, channel_axis=-1, \n",
    "#                         data_range=pred_masked.max() - pred_masked.min()\n",
    "#                     )\n",
    "#                 )\n",
    "#     return np.mean(scores) if scores else 0.0\n",
    "\n",
    "# # 모델 초기화 및 옵티마이저 설정\n",
    "# def initialize_models_and_optimizers():\n",
    "#     generator = GeneratorModel().to(device)  # GeneratorModel을 실제 모델로 변경\n",
    "#     discriminator = PatchGANDiscriminator().to(device)\n",
    "#     optimizer_G = optim.Adam(generator.parameters(), lr=CFG[\"LEARNING_RATE\"])\n",
    "#     optimizer_D = optim.Adam(discriminator.parameters(), lr=CFG[\"LEARNING_RATE\"])\n",
    "#     return generator, discriminator, optimizer_G, optimizer_D\n",
    "\n",
    "# # 학습 단계 함수\n",
    "# def train_step(generator, discriminator, optimizer_G, optimizer_D, batch):\n",
    "#     real_A = batch['A'].to(device)  # 손상된 이미지\n",
    "#     real_B = batch['B'].to(device)  # 원본 이미지\n",
    "#     mask = batch.get('mask', None)  # 'mask'가 없을 경우 None으로 설정\n",
    "#     if mask is not None and torch.any(mask):\n",
    "#         mask = mask.to(device)\n",
    "#     else:\n",
    "#         mask = None\n",
    "\n",
    "#     # Generator 훈련\n",
    "#     optimizer_G.zero_grad()\n",
    "#     fake_B = generator(real_A)\n",
    "\n",
    "#     # 마스크된 부분만 손실 계산\n",
    "#     if mask is not None:\n",
    "#         fake_B_masked = fake_B * mask\n",
    "#         real_B_masked = real_B * mask\n",
    "#         loss_pixel = criterion_pixelwise(fake_B_masked, real_B_masked)\n",
    "#     else:\n",
    "#         loss_pixel = criterion_pixelwise(fake_B, real_B)\n",
    "    \n",
    "#     pred_fake = discriminator(fake_B, real_A)\n",
    "#     loss_GAN = criterion_GAN(pred_fake, torch.ones_like(pred_fake).to(device))\n",
    "#     loss_G = loss_GAN + lambda_pixel * loss_pixel\n",
    "#     loss_G.backward()\n",
    "#     optimizer_G.step()\n",
    "\n",
    "#     # Discriminator 훈련\n",
    "#     optimizer_D.zero_grad()\n",
    "#     pred_real = discriminator(real_B, real_A)\n",
    "#     loss_real = criterion_GAN(pred_real, torch.ones_like(pred_real).to(device))\n",
    "#     pred_fake = discriminator(fake_B.detach(), real_A)\n",
    "#     loss_fake = criterion_GAN(pred_fake, torch.zeros_like(pred_fake).to(device))\n",
    "#     loss_D = 0.5 * (loss_real + loss_fake)\n",
    "#     loss_D.backward()\n",
    "#     optimizer_D.step()\n",
    "\n",
    "#     return loss_G.item(), loss_D.item()\n",
    "\n",
    "# # 검증 단계 함수\n",
    "# def validate(generator, validation_dataloader):\n",
    "#     generator.eval()\n",
    "#     validation_loss, ssim_scores, masked_ssim_scores, hist_similarities = 0, [], [], []\n",
    "#     with torch.no_grad():\n",
    "#         for val_batch in validation_dataloader:\n",
    "#             real_val_A = val_batch['A'].to(device)\n",
    "#             real_val_B = val_batch['B'].to(device)\n",
    "#             fake_val_B = generator(real_val_A)\n",
    "    \n",
    "#             # SSIM 점수 계산\n",
    "#             ssim_value = ssim_score(real_val_B, fake_val_B)\n",
    "#             ssim_scores.append(ssim_value)\n",
    "    \n",
    "#             # 마스크가 있을 경우에만 masked_ssim 계산\n",
    "#             real_val_mask = val_batch.get('mask', None)\n",
    "#             if real_val_mask is not None:\n",
    "#                 real_val_mask = real_val_mask.to(device)\n",
    "#                 masked_ssim_value = masked_ssim_score(real_val_B, fake_val_B, real_val_mask)\n",
    "#                 masked_ssim_scores.append(masked_ssim_value)\n",
    "    \n",
    "#             # 히스토그램 유사도 계산\n",
    "#             hist_value = histogram_similarity(real_val_B, fake_val_B)\n",
    "#             hist_similarities.append(hist_value)\n",
    "\n",
    "#             # 검증 손실 계산 (루프 내부에서 누적)\n",
    "#             val_loss = criterion_pixelwise(fake_val_B, real_val_B).item()\n",
    "#             validation_loss += val_loss\n",
    "        \n",
    "#     # 검증 루프 이후에 평균 손실 계산 (루프 외부)\n",
    "#     validation_loss /= len(validation_dataloader)\n",
    "\n",
    "#     # 평균값 계산\n",
    "#     S = sum(ssim_scores) / len(ssim_scores)\n",
    "#     M = sum(masked_ssim_scores) / len(masked_ssim_scores) if len(masked_ssim_scores) > 0 else 0\n",
    "#     C = sum(hist_similarities) / len(hist_similarities)\n",
    "#     score = (0.2 * S) + (0.4 * M) + (0.4 * C)\n",
    "\n",
    "#     return validation_loss, score\n",
    "\n",
    "# # 모델 체크포인트 설정 예제 (조정된 모델 저장 경로 사용)\n",
    "# checkpoint_callback = ModelCheckpoint(\n",
    "#     dirpath=model_save_dir,\n",
    "#     filename='best_model-{epoch:02d}-{validation_loss:.4f}',\n",
    "#     save_top_k=1,\n",
    "#     verbose=True,\n",
    "#     monitor='validation_loss',  # 일관된 변수 이름 사용\n",
    "#     mode='min'\n",
    "# )\n",
    "\n",
    "# # EarlyStopping에서 모니터링하는 변수 이름을 일치시킴\n",
    "# early_stopping_callback = EarlyStopping(\n",
    "#     monitor='validation_loss',\n",
    "#     mode='min',\n",
    "#     patience=3\n",
    "# )\n",
    "\n",
    "# trainer = Trainer(\n",
    "#     max_epochs=CFG['EPOCHS'],\n",
    "#     callbacks=[checkpoint_callback, early_stopping_callback],\n",
    "#     gradient_clip_val=1.0,  # 그래디언트 클리핑 값 설정\n",
    "#     gpus=1,  # CUDA 사용을 명시적으로 지정\n",
    "#     precision=16  # 16-bit mixed precision 사용으로 메모리 절약 및 속도 향상\n",
    "# )\n",
    "\n",
    "# # 학습 및 검증 루프\n",
    "# generator, discriminator, optimizer_G, optimizer_D = initialize_models_and_optimizers()\n",
    "\n",
    "# for epoch in range(1, CFG['EPOCHS'] + 1):\n",
    "#     generator.train()  # Generator 학습 모드\n",
    "#     for i, batch in enumerate(train_dataloader):\n",
    "#         loss_G, loss_D = train_step(generator, discriminator, optimizer_G, optimizer_D, batch)\n",
    "#         # Batch 로그 출력\n",
    "#         print(f\"[Epoch {epoch}] [Batch {i}] [G loss: {loss_G}] [D loss: {loss_D}]\")\n",
    "\n",
    "#     # Validation 단계\n",
    "#     validation_loss, score = validate(generator, validation_dataloader)\n",
    "\n",
    "#     best_generator_path = os.path.join(model_save_dir, \"best_generator.pth\")\n",
    "#     best_discriminator_path = os.path.join(model_save_dir, \"best_discriminator.pth\")\n",
    "        \n",
    "#     # 모델 저장 조건\n",
    "#     if score > best_score:\n",
    "#         best_score = score\n",
    "#         torch.save(generator.state_dict(), best_generator_path)\n",
    "#         torch.save(discriminator.state_dict(), best_discriminator_path)\n",
    "\n",
    "#     # Validation 완료 후 Epoch 로그 출력\n",
    "#     print(f\"Epoch {epoch}: Validation loss: {validation_loss:.4f}, Score: {score:.4f}, Best Score: {best_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-18T09:26:50.765457Z",
     "iopub.status.idle": "2024-11-18T09:26:50.765969Z",
     "shell.execute_reply": "2024-11-18T09:26:50.765730Z",
     "shell.execute_reply.started": "2024-11-18T09:26:50.765704Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 저장할 디렉토리 설정\n",
    "model_save_dir = \"./saved_models\"\n",
    "submission_dir = \"./submission\"\n",
    "os.makedirs(submission_dir, exist_ok=True)\n",
    "\n",
    "# 이미지 로드 및 전처리\n",
    "def load_image(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = transform(image)\n",
    "    image = image.unsqueeze(0)  # 배치 차원을 추가합니다.\n",
    "    return image\n",
    "\n",
    "# 모델 경로 설정\n",
    "generator_path = os.path.join(\"/kaggle/input/best-model01/best_generator (1).pth\")\n",
    "\n",
    "# 모델 로드 및 설정\n",
    "# model = UNetPP(in_channels=3, out_channels=3).to(device)  # UNetPP로 설정\n",
    "UNetPP.load_state_dict(torch.load(generator_path))\n",
    "UNetPP.eval()\n",
    "\n",
    "# 파일 리스트 불러오기\n",
    "test_images = sorted(os.listdir(test_dir))\n",
    "\n",
    "# 모든 테스트 이미지에 대해 추론 수행\n",
    "for image_name in test_images:\n",
    "    test_image_path = os.path.join(test_dir, image_name)\n",
    "\n",
    "    # 손상된 테스트 이미지 로드 및 전처리\n",
    "    test_image = load_image(test_image_path).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # 모델로 예측\n",
    "        pred_image = UNetPP(test_image)\n",
    "        pred_image = pred_image.cpu().squeeze(0)  # 배치 차원 제거\n",
    "        pred_image = pred_image * 0.5 + 0.5  # 역정규화\n",
    "        pred_image = pred_image.numpy().transpose(1, 2, 0)  # HWC로 변경\n",
    "        pred_image = (pred_image * 255).astype('uint8')  # 0-255 범위로 변환\n",
    "        \n",
    "        # 예측된 이미지를 실제 이미지와 같은 512x512로 리사이즈\n",
    "        pred_image_resized = cv2.resize(pred_image, (512, 512), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    # 결과 이미지 저장\n",
    "    output_path = os.path.join(submission_dir, image_name)\n",
    "    cv2.imwrite(output_path, cv2.cvtColor(pred_image_resized, cv2.COLOR_RGB2BGR))    \n",
    "    \n",
    "print(f\"Saved all images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T09:11:51.006020Z",
     "iopub.status.busy": "2024-11-18T09:11:51.005310Z",
     "iopub.status.idle": "2024-11-18T09:11:51.130683Z",
     "shell.execute_reply": "2024-11-18T09:11:51.129745Z",
     "shell.execute_reply.started": "2024-11-18T09:11:51.005970Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 저장된 결과 이미지를 ZIP 파일로 압축\n",
    "zip_filename = \"submission1.zip\"\n",
    "with zipfile.ZipFile(zip_filename, 'w') as submission_zip:\n",
    "    for image_name in test_images:\n",
    "        image_path = os.path.join(submission_dir, image_name)\n",
    "        submission_zip.write(image_path, arcname=image_name)\n",
    "\n",
    "print(f\"All images saved in {zip_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T02:15:56.140763Z",
     "iopub.status.busy": "2024-11-15T02:15:56.140088Z",
     "iopub.status.idle": "2024-11-15T02:15:57.214677Z",
     "shell.execute_reply": "2024-11-15T02:15:57.213429Z",
     "shell.execute_reply.started": "2024-11-15T02:15:56.140720Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6075062,
     "sourceId": 9891694,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6078662,
     "sourceId": 9896364,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6111024,
     "sourceId": 9939640,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
